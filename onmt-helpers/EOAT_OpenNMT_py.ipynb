{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "EOAT-OpenNMT-py.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jenh/epub-ocr-and-translate/blob/master/onmt-helpers/EOAT_OpenNMT_py.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OLumcVxCSG3s",
        "colab_type": "text"
      },
      "source": [
        "# Setup"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tiZNxlOICSJY",
        "colab_type": "text"
      },
      "source": [
        "Install OpenNMT-py and connect to Google Drive:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "izaMW_tkisR4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install opennmt-py"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bqjg2aONiC9j",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "393b1925-000b-4d75-af6f-221b3416b057"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x4yMhyRmBj3h",
        "colab_type": "text"
      },
      "source": [
        "# Get some sample data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SCkYiohBBoU_",
        "colab_type": "text"
      },
      "source": [
        "Let's check out the OpenNMT-py project to grab some sample data to process. Google Colab will check out to /content and our sample data resides in /content/OpenNMT-py/data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OF_BTT8bBuX6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!git clone https://github.com/OpenNMT/OpenNMT-py"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z3QhhNNYSOlO",
        "colab_type": "text"
      },
      "source": [
        "# Preprocess"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y-64jYCCScjl",
        "colab_type": "text"
      },
      "source": [
        "Preprocess files. This command is vanilla, no bpe or sentencepiece or any other special sauce, we're training straight from corpus --- you can customize this as needed."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VHaqWBrsHDIH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!onmt_preprocess -train_src /content/OpenNMT-py/data/src-train.txt \\\\\n",
        "-train_tgt /content/OpenNMT-py/data/tgt-train.txt \\\\\n",
        "-valid_src /content/OpenNMT-py/data/src-val.txt \\\\\n",
        "-valid_tgt /content/OpenNMT-py/data/tgt-val.txt \\\\\n",
        "-save_data /content/drive/My\\ Drive/my_train_data --lower \\\\\n",
        "--share_vocab\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eZSOvunTSc8Y",
        "colab_type": "text"
      },
      "source": [
        "# Check GPU"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_7b8DWuvCZmT",
        "colab_type": "text"
      },
      "source": [
        "Verify GPU status."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hKjnQoltKFDk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!nvidia-smi\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P-hZ_U1QSizx",
        "colab_type": "text"
      },
      "source": [
        "# Train (First run)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "78NmaDXLClI3",
        "colab_type": "text"
      },
      "source": [
        "Create and run a training command like the following (yours may differ based on what your aims are --- I've cribbed my settings based on a lot of Googling, and they are as always subject to change). On Google Colab, you want -world_size 1 (we have one GPU available to us) and -gpu_ranks 0 (its id is 0).\n",
        "\n",
        "The steps are also really low here, just so that you can get quicker results with sample data. The second run of training has more realistic numbers."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-XJTgKy_OpRN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!onmt_train -data /content/drive/My\\ Drive/my_train_data \\\\\n",
        "-save_model /content/drive/My\\ Drive/my-model \\\\\n",
        "-layers 6 -rnn_size 512 -word_vec_size 512 -transformer_ff 2048 -heads 8 \\\\\n",
        "-encoder_type transformer -decoder_type transformer -position_encoding \\\\\n",
        "-train_steps 3000  -max_generator_batches 2 -dropout 0.1 -batch_size 4096 \\\\\n",
        "-batch_type tokens -normalization tokens  -accum_count 2 -optim adam -adam_beta2 0.998 \\\\\n",
        "-decay_method noam -learning_rate 2 -max_grad_norm 0 -param_init 0 \\\\\n",
        "-param_init_glorot -label_smoothing 0.1 -valid_steps 1000 -save_checkpoint_steps 1000 \\\\\n",
        "-report_every 1000 -world_size 1 -gpu_ranks 0\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7fqdB9ZCFCWi",
        "colab_type": "text"
      },
      "source": [
        "# Train (from model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fJ9xUO7_Dohc",
        "colab_type": "text"
      },
      "source": [
        "Once you've been interrupted, restart training with -train_from to start where you left off."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6ZGfj9DBkGR_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!onmt_train -data /content/drive/My\\ Drive/my_train_data \\\\\n",
        "-save_model /content/drive/My\\ Drive/my-2nd-model \\\\\n",
        "-train_from /content/drive/My\\ Drive/my-model_step_1000.pt \\\\\n",
        "-layers 6 -rnn_size 512 -word_vec_size 512 -transformer_ff 2048 -heads 8 \\\\\n",
        "-encoder_type transformer -decoder_type transformer -position_encoding \\\\\n",
        "-train_steps 200000  -max_generator_batches 2 -dropout 0.1 -batch_size 4096 \\\\\n",
        "-batch_type tokens -normalization tokens  -accum_count 2 -optim adam -adam_beta2 0.998 \\\\\n",
        "-decay_method noam -warmup_steps 8000 -learning_rate 2 -max_grad_norm 0 -param_init 0 \\\\\n",
        "-param_init_glorot -label_smoothing 0.1 -valid_steps 10000 -save_checkpoint_steps 3000 \\\\\n",
        "-report_every 1000 -world_size 1 -gpu_ranks 0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qkMnTATNFodA",
        "colab_type": "text"
      },
      "source": [
        "# Translate"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TSrxcej3FroV",
        "colab_type": "text"
      },
      "source": [
        "Now that you've got a model, you're ready to translate! Let's use the sample data from the OpenNMT-py project."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fbaaTlRRFy8d",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!onmt_translate --model /content/drive/My\\ Drive/my-model_step_1000.pt \\\\\n",
        "--src /content/OpenNMT-py/data/src-test.txt --output /content/drive/My\\ Drive/translation-output.txt \\\\\n",
        "--replace_unk -verbose"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "amhvKcRHW6hY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!cat /content/drive/My\\ Drive/translation-output.txt"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}